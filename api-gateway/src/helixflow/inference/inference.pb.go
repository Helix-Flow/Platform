// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.11
// 	protoc        v3.21.12
// source: inference.proto

package inference

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// Message structure
type Message struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Role          string                 `protobuf:"bytes,1,opt,name=role,proto3" json:"role,omitempty"`
	Content       string                 `protobuf:"bytes,2,opt,name=content,proto3" json:"content,omitempty"`
	Name          string                 `protobuf:"bytes,3,opt,name=name,proto3" json:"name,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Message) Reset() {
	*x = Message{}
	mi := &file_inference_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Message) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Message) ProtoMessage() {}

func (x *Message) ProtoReflect() protoreflect.Message {
	mi := &file_inference_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Message.ProtoReflect.Descriptor instead.
func (*Message) Descriptor() ([]byte, []int) {
	return file_inference_proto_rawDescGZIP(), []int{0}
}

func (x *Message) GetRole() string {
	if x != nil {
		return x.Role
	}
	return ""
}

func (x *Message) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

func (x *Message) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

// Inference request
type InferenceRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Model         string                 `protobuf:"bytes,1,opt,name=model,proto3" json:"model,omitempty"`
	Messages      []*Message             `protobuf:"bytes,2,rep,name=messages,proto3" json:"messages,omitempty"`
	MaxTokens     int32                  `protobuf:"varint,3,opt,name=max_tokens,json=maxTokens,proto3" json:"max_tokens,omitempty"`
	Temperature   float32                `protobuf:"fixed32,4,opt,name=temperature,proto3" json:"temperature,omitempty"`
	TopP          float32                `protobuf:"fixed32,5,opt,name=top_p,json=topP,proto3" json:"top_p,omitempty"`
	TopK          int32                  `protobuf:"varint,6,opt,name=top_k,json=topK,proto3" json:"top_k,omitempty"`
	Stream        bool                   `protobuf:"varint,7,opt,name=stream,proto3" json:"stream,omitempty"`
	UserId        string                 `protobuf:"bytes,8,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`
	Metadata      map[string]string      `protobuf:"bytes,9,rep,name=metadata,proto3" json:"metadata,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *InferenceRequest) Reset() {
	*x = InferenceRequest{}
	mi := &file_inference_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferenceRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferenceRequest) ProtoMessage() {}

func (x *InferenceRequest) ProtoReflect() protoreflect.Message {
	mi := &file_inference_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferenceRequest.ProtoReflect.Descriptor instead.
func (*InferenceRequest) Descriptor() ([]byte, []int) {
	return file_inference_proto_rawDescGZIP(), []int{1}
}

func (x *InferenceRequest) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *InferenceRequest) GetMessages() []*Message {
	if x != nil {
		return x.Messages
	}
	return nil
}

func (x *InferenceRequest) GetMaxTokens() int32 {
	if x != nil {
		return x.MaxTokens
	}
	return 0
}

func (x *InferenceRequest) GetTemperature() float32 {
	if x != nil {
		return x.Temperature
	}
	return 0
}

func (x *InferenceRequest) GetTopP() float32 {
	if x != nil {
		return x.TopP
	}
	return 0
}

func (x *InferenceRequest) GetTopK() int32 {
	if x != nil {
		return x.TopK
	}
	return 0
}

func (x *InferenceRequest) GetStream() bool {
	if x != nil {
		return x.Stream
	}
	return false
}

func (x *InferenceRequest) GetUserId() string {
	if x != nil {
		return x.UserId
	}
	return ""
}

func (x *InferenceRequest) GetMetadata() map[string]string {
	if x != nil {
		return x.Metadata
	}
	return nil
}

// Inference response
type InferenceResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Content       string                 `protobuf:"bytes,1,opt,name=content,proto3" json:"content,omitempty"`
	FinishReason  string                 `protobuf:"bytes,2,opt,name=finish_reason,json=finishReason,proto3" json:"finish_reason,omitempty"`
	Usage         *Usage                 `protobuf:"bytes,3,opt,name=usage,proto3" json:"usage,omitempty"`
	Model         string                 `protobuf:"bytes,4,opt,name=model,proto3" json:"model,omitempty"`
	Created       int64                  `protobuf:"varint,5,opt,name=created,proto3" json:"created,omitempty"`
	Id            string                 `protobuf:"bytes,6,opt,name=id,proto3" json:"id,omitempty"`
	Metadata      map[string]string      `protobuf:"bytes,7,rep,name=metadata,proto3" json:"metadata,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *InferenceResponse) Reset() {
	*x = InferenceResponse{}
	mi := &file_inference_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferenceResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferenceResponse) ProtoMessage() {}

func (x *InferenceResponse) ProtoReflect() protoreflect.Message {
	mi := &file_inference_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferenceResponse.ProtoReflect.Descriptor instead.
func (*InferenceResponse) Descriptor() ([]byte, []int) {
	return file_inference_proto_rawDescGZIP(), []int{2}
}

func (x *InferenceResponse) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

func (x *InferenceResponse) GetFinishReason() string {
	if x != nil {
		return x.FinishReason
	}
	return ""
}

func (x *InferenceResponse) GetUsage() *Usage {
	if x != nil {
		return x.Usage
	}
	return nil
}

func (x *InferenceResponse) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *InferenceResponse) GetCreated() int64 {
	if x != nil {
		return x.Created
	}
	return 0
}

func (x *InferenceResponse) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *InferenceResponse) GetMetadata() map[string]string {
	if x != nil {
		return x.Metadata
	}
	return nil
}

// Usage information
type Usage struct {
	state            protoimpl.MessageState `protogen:"open.v1"`
	PromptTokens     int32                  `protobuf:"varint,1,opt,name=prompt_tokens,json=promptTokens,proto3" json:"prompt_tokens,omitempty"`
	CompletionTokens int32                  `protobuf:"varint,2,opt,name=completion_tokens,json=completionTokens,proto3" json:"completion_tokens,omitempty"`
	TotalTokens      int32                  `protobuf:"varint,3,opt,name=total_tokens,json=totalTokens,proto3" json:"total_tokens,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *Usage) Reset() {
	*x = Usage{}
	mi := &file_inference_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Usage) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Usage) ProtoMessage() {}

func (x *Usage) ProtoReflect() protoreflect.Message {
	mi := &file_inference_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Usage.ProtoReflect.Descriptor instead.
func (*Usage) Descriptor() ([]byte, []int) {
	return file_inference_proto_rawDescGZIP(), []int{3}
}

func (x *Usage) GetPromptTokens() int32 {
	if x != nil {
		return x.PromptTokens
	}
	return 0
}

func (x *Usage) GetCompletionTokens() int32 {
	if x != nil {
		return x.CompletionTokens
	}
	return 0
}

func (x *Usage) GetTotalTokens() int32 {
	if x != nil {
		return x.TotalTokens
	}
	return 0
}

// Model info request
type ModelInfoRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	ModelId       string                 `protobuf:"bytes,1,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ModelInfoRequest) Reset() {
	*x = ModelInfoRequest{}
	mi := &file_inference_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelInfoRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelInfoRequest) ProtoMessage() {}

func (x *ModelInfoRequest) ProtoReflect() protoreflect.Message {
	mi := &file_inference_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelInfoRequest.ProtoReflect.Descriptor instead.
func (*ModelInfoRequest) Descriptor() ([]byte, []int) {
	return file_inference_proto_rawDescGZIP(), []int{4}
}

func (x *ModelInfoRequest) GetModelId() string {
	if x != nil {
		return x.ModelId
	}
	return ""
}

// Model info response
type ModelInfoResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Id            string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	Name          string                 `protobuf:"bytes,2,opt,name=name,proto3" json:"name,omitempty"`
	Description   string                 `protobuf:"bytes,3,opt,name=description,proto3" json:"description,omitempty"`
	Provider      string                 `protobuf:"bytes,4,opt,name=provider,proto3" json:"provider,omitempty"`
	Created       int64                  `protobuf:"varint,5,opt,name=created,proto3" json:"created,omitempty"`
	Capabilities  map[string]string      `protobuf:"bytes,6,rep,name=capabilities,proto3" json:"capabilities,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	Active        bool                   `protobuf:"varint,7,opt,name=active,proto3" json:"active,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ModelInfoResponse) Reset() {
	*x = ModelInfoResponse{}
	mi := &file_inference_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelInfoResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelInfoResponse) ProtoMessage() {}

func (x *ModelInfoResponse) ProtoReflect() protoreflect.Message {
	mi := &file_inference_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelInfoResponse.ProtoReflect.Descriptor instead.
func (*ModelInfoResponse) Descriptor() ([]byte, []int) {
	return file_inference_proto_rawDescGZIP(), []int{5}
}

func (x *ModelInfoResponse) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *ModelInfoResponse) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *ModelInfoResponse) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *ModelInfoResponse) GetProvider() string {
	if x != nil {
		return x.Provider
	}
	return ""
}

func (x *ModelInfoResponse) GetCreated() int64 {
	if x != nil {
		return x.Created
	}
	return 0
}

func (x *ModelInfoResponse) GetCapabilities() map[string]string {
	if x != nil {
		return x.Capabilities
	}
	return nil
}

func (x *ModelInfoResponse) GetActive() bool {
	if x != nil {
		return x.Active
	}
	return false
}

// List models request
type ListModelsRequest struct {
	state           protoimpl.MessageState `protogen:"open.v1"`
	UserId          string                 `protobuf:"bytes,1,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`
	IncludeInactive bool                   `protobuf:"varint,2,opt,name=include_inactive,json=includeInactive,proto3" json:"include_inactive,omitempty"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *ListModelsRequest) Reset() {
	*x = ListModelsRequest{}
	mi := &file_inference_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListModelsRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListModelsRequest) ProtoMessage() {}

func (x *ListModelsRequest) ProtoReflect() protoreflect.Message {
	mi := &file_inference_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListModelsRequest.ProtoReflect.Descriptor instead.
func (*ListModelsRequest) Descriptor() ([]byte, []int) {
	return file_inference_proto_rawDescGZIP(), []int{6}
}

func (x *ListModelsRequest) GetUserId() string {
	if x != nil {
		return x.UserId
	}
	return ""
}

func (x *ListModelsRequest) GetIncludeInactive() bool {
	if x != nil {
		return x.IncludeInactive
	}
	return false
}

// List models response
type ListModelsResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Models        []*ModelInfoResponse   `protobuf:"bytes,1,rep,name=models,proto3" json:"models,omitempty"`
	TotalCount    int32                  `protobuf:"varint,2,opt,name=total_count,json=totalCount,proto3" json:"total_count,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListModelsResponse) Reset() {
	*x = ListModelsResponse{}
	mi := &file_inference_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListModelsResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListModelsResponse) ProtoMessage() {}

func (x *ListModelsResponse) ProtoReflect() protoreflect.Message {
	mi := &file_inference_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListModelsResponse.ProtoReflect.Descriptor instead.
func (*ListModelsResponse) Descriptor() ([]byte, []int) {
	return file_inference_proto_rawDescGZIP(), []int{7}
}

func (x *ListModelsResponse) GetModels() []*ModelInfoResponse {
	if x != nil {
		return x.Models
	}
	return nil
}

func (x *ListModelsResponse) GetTotalCount() int32 {
	if x != nil {
		return x.TotalCount
	}
	return 0
}

// Health check request
type HealthRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *HealthRequest) Reset() {
	*x = HealthRequest{}
	mi := &file_inference_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HealthRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HealthRequest) ProtoMessage() {}

func (x *HealthRequest) ProtoReflect() protoreflect.Message {
	mi := &file_inference_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HealthRequest.ProtoReflect.Descriptor instead.
func (*HealthRequest) Descriptor() ([]byte, []int) {
	return file_inference_proto_rawDescGZIP(), []int{8}
}

// Health check response
type HealthResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Status        string                 `protobuf:"bytes,1,opt,name=status,proto3" json:"status,omitempty"`
	Version       string                 `protobuf:"bytes,2,opt,name=version,proto3" json:"version,omitempty"`
	Timestamp     int64                  `protobuf:"varint,3,opt,name=timestamp,proto3" json:"timestamp,omitempty"`
	Details       map[string]string      `protobuf:"bytes,4,rep,name=details,proto3" json:"details,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *HealthResponse) Reset() {
	*x = HealthResponse{}
	mi := &file_inference_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HealthResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HealthResponse) ProtoMessage() {}

func (x *HealthResponse) ProtoReflect() protoreflect.Message {
	mi := &file_inference_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HealthResponse.ProtoReflect.Descriptor instead.
func (*HealthResponse) Descriptor() ([]byte, []int) {
	return file_inference_proto_rawDescGZIP(), []int{9}
}

func (x *HealthResponse) GetStatus() string {
	if x != nil {
		return x.Status
	}
	return ""
}

func (x *HealthResponse) GetVersion() string {
	if x != nil {
		return x.Version
	}
	return ""
}

func (x *HealthResponse) GetTimestamp() int64 {
	if x != nil {
		return x.Timestamp
	}
	return 0
}

func (x *HealthResponse) GetDetails() map[string]string {
	if x != nil {
		return x.Details
	}
	return nil
}

var File_inference_proto protoreflect.FileDescriptor

const file_inference_proto_rawDesc = "" +
	"\n" +
	"\x0finference.proto\x12\x13helixflow.inference\"K\n" +
	"\aMessage\x12\x12\n" +
	"\x04role\x18\x01 \x01(\tR\x04role\x12\x18\n" +
	"\acontent\x18\x02 \x01(\tR\acontent\x12\x12\n" +
	"\x04name\x18\x03 \x01(\tR\x04name\"\x8c\x03\n" +
	"\x10InferenceRequest\x12\x14\n" +
	"\x05model\x18\x01 \x01(\tR\x05model\x128\n" +
	"\bmessages\x18\x02 \x03(\v2\x1c.helixflow.inference.MessageR\bmessages\x12\x1d\n" +
	"\n" +
	"max_tokens\x18\x03 \x01(\x05R\tmaxTokens\x12 \n" +
	"\vtemperature\x18\x04 \x01(\x02R\vtemperature\x12\x13\n" +
	"\x05top_p\x18\x05 \x01(\x02R\x04topP\x12\x13\n" +
	"\x05top_k\x18\x06 \x01(\x05R\x04topK\x12\x16\n" +
	"\x06stream\x18\a \x01(\bR\x06stream\x12\x17\n" +
	"\auser_id\x18\b \x01(\tR\x06userId\x12O\n" +
	"\bmetadata\x18\t \x03(\v23.helixflow.inference.InferenceRequest.MetadataEntryR\bmetadata\x1a;\n" +
	"\rMetadataEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\xd3\x02\n" +
	"\x11InferenceResponse\x12\x18\n" +
	"\acontent\x18\x01 \x01(\tR\acontent\x12#\n" +
	"\rfinish_reason\x18\x02 \x01(\tR\ffinishReason\x120\n" +
	"\x05usage\x18\x03 \x01(\v2\x1a.helixflow.inference.UsageR\x05usage\x12\x14\n" +
	"\x05model\x18\x04 \x01(\tR\x05model\x12\x18\n" +
	"\acreated\x18\x05 \x01(\x03R\acreated\x12\x0e\n" +
	"\x02id\x18\x06 \x01(\tR\x02id\x12P\n" +
	"\bmetadata\x18\a \x03(\v24.helixflow.inference.InferenceResponse.MetadataEntryR\bmetadata\x1a;\n" +
	"\rMetadataEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"|\n" +
	"\x05Usage\x12#\n" +
	"\rprompt_tokens\x18\x01 \x01(\x05R\fpromptTokens\x12+\n" +
	"\x11completion_tokens\x18\x02 \x01(\x05R\x10completionTokens\x12!\n" +
	"\ftotal_tokens\x18\x03 \x01(\x05R\vtotalTokens\"-\n" +
	"\x10ModelInfoRequest\x12\x19\n" +
	"\bmodel_id\x18\x01 \x01(\tR\amodelId\"\xc6\x02\n" +
	"\x11ModelInfoResponse\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x12\x12\n" +
	"\x04name\x18\x02 \x01(\tR\x04name\x12 \n" +
	"\vdescription\x18\x03 \x01(\tR\vdescription\x12\x1a\n" +
	"\bprovider\x18\x04 \x01(\tR\bprovider\x12\x18\n" +
	"\acreated\x18\x05 \x01(\x03R\acreated\x12\\\n" +
	"\fcapabilities\x18\x06 \x03(\v28.helixflow.inference.ModelInfoResponse.CapabilitiesEntryR\fcapabilities\x12\x16\n" +
	"\x06active\x18\a \x01(\bR\x06active\x1a?\n" +
	"\x11CapabilitiesEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"W\n" +
	"\x11ListModelsRequest\x12\x17\n" +
	"\auser_id\x18\x01 \x01(\tR\x06userId\x12)\n" +
	"\x10include_inactive\x18\x02 \x01(\bR\x0fincludeInactive\"u\n" +
	"\x12ListModelsResponse\x12>\n" +
	"\x06models\x18\x01 \x03(\v2&.helixflow.inference.ModelInfoResponseR\x06models\x12\x1f\n" +
	"\vtotal_count\x18\x02 \x01(\x05R\n" +
	"totalCount\"\x0f\n" +
	"\rHealthRequest\"\xe8\x01\n" +
	"\x0eHealthResponse\x12\x16\n" +
	"\x06status\x18\x01 \x01(\tR\x06status\x12\x18\n" +
	"\aversion\x18\x02 \x01(\tR\aversion\x12\x1c\n" +
	"\ttimestamp\x18\x03 \x01(\x03R\ttimestamp\x12J\n" +
	"\adetails\x18\x04 \x03(\v20.helixflow.inference.HealthResponse.DetailsEntryR\adetails\x1a:\n" +
	"\fDetailsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x012\xf8\x03\n" +
	"\x10InferenceService\x12c\n" +
	"\x12GenerateCompletion\x12%.helixflow.inference.InferenceRequest\x1a&.helixflow.inference.InferenceResponse\x12n\n" +
	"\x1bGenerateStreamingCompletion\x12%.helixflow.inference.InferenceRequest\x1a&.helixflow.inference.InferenceResponse0\x01\x12]\n" +
	"\fGetModelInfo\x12%.helixflow.inference.ModelInfoRequest\x1a&.helixflow.inference.ModelInfoResponse\x12]\n" +
	"\n" +
	"ListModels\x12&.helixflow.inference.ListModelsRequest\x1a'.helixflow.inference.ListModelsResponse\x12Q\n" +
	"\x06Health\x12\".helixflow.inference.HealthRequest\x1a#.helixflow.inference.HealthResponseB\x15Z\x13helixflow/inferenceb\x06proto3"

var (
	file_inference_proto_rawDescOnce sync.Once
	file_inference_proto_rawDescData []byte
)

func file_inference_proto_rawDescGZIP() []byte {
	file_inference_proto_rawDescOnce.Do(func() {
		file_inference_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_inference_proto_rawDesc), len(file_inference_proto_rawDesc)))
	})
	return file_inference_proto_rawDescData
}

var file_inference_proto_msgTypes = make([]protoimpl.MessageInfo, 14)
var file_inference_proto_goTypes = []any{
	(*Message)(nil),            // 0: helixflow.inference.Message
	(*InferenceRequest)(nil),   // 1: helixflow.inference.InferenceRequest
	(*InferenceResponse)(nil),  // 2: helixflow.inference.InferenceResponse
	(*Usage)(nil),              // 3: helixflow.inference.Usage
	(*ModelInfoRequest)(nil),   // 4: helixflow.inference.ModelInfoRequest
	(*ModelInfoResponse)(nil),  // 5: helixflow.inference.ModelInfoResponse
	(*ListModelsRequest)(nil),  // 6: helixflow.inference.ListModelsRequest
	(*ListModelsResponse)(nil), // 7: helixflow.inference.ListModelsResponse
	(*HealthRequest)(nil),      // 8: helixflow.inference.HealthRequest
	(*HealthResponse)(nil),     // 9: helixflow.inference.HealthResponse
	nil,                        // 10: helixflow.inference.InferenceRequest.MetadataEntry
	nil,                        // 11: helixflow.inference.InferenceResponse.MetadataEntry
	nil,                        // 12: helixflow.inference.ModelInfoResponse.CapabilitiesEntry
	nil,                        // 13: helixflow.inference.HealthResponse.DetailsEntry
}
var file_inference_proto_depIdxs = []int32{
	0,  // 0: helixflow.inference.InferenceRequest.messages:type_name -> helixflow.inference.Message
	10, // 1: helixflow.inference.InferenceRequest.metadata:type_name -> helixflow.inference.InferenceRequest.MetadataEntry
	3,  // 2: helixflow.inference.InferenceResponse.usage:type_name -> helixflow.inference.Usage
	11, // 3: helixflow.inference.InferenceResponse.metadata:type_name -> helixflow.inference.InferenceResponse.MetadataEntry
	12, // 4: helixflow.inference.ModelInfoResponse.capabilities:type_name -> helixflow.inference.ModelInfoResponse.CapabilitiesEntry
	5,  // 5: helixflow.inference.ListModelsResponse.models:type_name -> helixflow.inference.ModelInfoResponse
	13, // 6: helixflow.inference.HealthResponse.details:type_name -> helixflow.inference.HealthResponse.DetailsEntry
	1,  // 7: helixflow.inference.InferenceService.GenerateCompletion:input_type -> helixflow.inference.InferenceRequest
	1,  // 8: helixflow.inference.InferenceService.GenerateStreamingCompletion:input_type -> helixflow.inference.InferenceRequest
	4,  // 9: helixflow.inference.InferenceService.GetModelInfo:input_type -> helixflow.inference.ModelInfoRequest
	6,  // 10: helixflow.inference.InferenceService.ListModels:input_type -> helixflow.inference.ListModelsRequest
	8,  // 11: helixflow.inference.InferenceService.Health:input_type -> helixflow.inference.HealthRequest
	2,  // 12: helixflow.inference.InferenceService.GenerateCompletion:output_type -> helixflow.inference.InferenceResponse
	2,  // 13: helixflow.inference.InferenceService.GenerateStreamingCompletion:output_type -> helixflow.inference.InferenceResponse
	5,  // 14: helixflow.inference.InferenceService.GetModelInfo:output_type -> helixflow.inference.ModelInfoResponse
	7,  // 15: helixflow.inference.InferenceService.ListModels:output_type -> helixflow.inference.ListModelsResponse
	9,  // 16: helixflow.inference.InferenceService.Health:output_type -> helixflow.inference.HealthResponse
	12, // [12:17] is the sub-list for method output_type
	7,  // [7:12] is the sub-list for method input_type
	7,  // [7:7] is the sub-list for extension type_name
	7,  // [7:7] is the sub-list for extension extendee
	0,  // [0:7] is the sub-list for field type_name
}

func init() { file_inference_proto_init() }
func file_inference_proto_init() {
	if File_inference_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_inference_proto_rawDesc), len(file_inference_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   14,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_inference_proto_goTypes,
		DependencyIndexes: file_inference_proto_depIdxs,
		MessageInfos:      file_inference_proto_msgTypes,
	}.Build()
	File_inference_proto = out.File
	file_inference_proto_goTypes = nil
	file_inference_proto_depIdxs = nil
}
