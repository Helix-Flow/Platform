openapi: 3.0.3
info:
  title: HelixFlow AI Inference API
  version: 1.0.0
  description: OpenAI-compatible API for AI model inference with HelixFlow extensions
  contact:
    name: HelixFlow Support
    email: support@helixflow.ai

servers:
  - url: https://api.helixflow.ai/v1
    description: Production server
  - url: https://staging-api.helixflow.ai/v1
    description: Staging server

security:
  - BearerAuth: []

paths:
  /chat/completions:
    post:
      summary: Create a chat completion
      description: Creates a completion for the chat message using the specified AI model
      operationId: createChatCompletion
      tags:
        - Chat
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatCompletionRequest'
            examples:
              simple-chat:
                summary: Simple chat completion
                value:
                  model: gpt-4
                  messages:
                    - role: user
                      content: Hello, how are you?
                  max_tokens: 100
              streaming-chat:
                summary: Streaming chat completion
                value:
                  model: claude-3-sonnet
                  messages:
                    - role: user
                      content: Write a short story
                  stream: true
                  temperature: 0.8
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionResponse'
            text/plain:
              schema:
                description: Streaming response (when stream=true)
                type: string
        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '429':
          $ref: '#/components/responses/RateLimitExceeded'
        '500':
          $ref: '#/components/responses/InternalServerError'

  /models:
    get:
      summary: List available models
      description: Lists all available AI models and their capabilities
      operationId: listModels
      tags:
        - Models
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListModelsResponse'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '500':
          $ref: '#/components/responses/InternalServerError'

  /models/{model}:
    get:
      summary: Retrieve a model
      description: Retrieves detailed information about a specific AI model
      operationId: retrieveModel
      tags:
        - Models
      parameters:
        - name: model
          in: path
          required: true
          schema:
            type: string
          description: The ID of the model to retrieve
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Model'
        '404':
          description: Model not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'
        '401':
          $ref: '#/components/responses/Unauthorized'

components:
  securitySchemes:
    BearerAuth:
      type: http
      scheme: bearer
      bearerFormat: JWT

  schemas:
    ChatCompletionRequest:
      type: object
      required:
        - model
        - messages
      properties:
        model:
          type: string
          description: The model to use for completion
          example: gpt-4
        messages:
          type: array
          minItems: 1
          items:
            $ref: '#/components/schemas/ChatMessage'
          description: A list of messages comprising the conversation
        max_tokens:
          type: integer
          minimum: 1
          maximum: 4096
          description: The maximum number of tokens to generate
          example: 100
        temperature:
          type: number
          minimum: 0
          maximum: 2
          description: Controls randomness in the output
          example: 0.7
        stream:
          type: boolean
          description: Whether to stream the response
          example: false
        user:
          type: string
          description: A unique identifier representing your end-user
          example: user123

    ChatMessage:
      type: object
      required:
        - role
        - content
      properties:
        role:
          type: string
          enum: [system, user, assistant]
          description: The role of the message author
        content:
          type: string
          description: The content of the message
        name:
          type: string
          description: An optional name for the participant

    ChatCompletionResponse:
      type: object
      required:
        - id
        - object
        - created
        - model
        - choices
        - usage
      properties:
        id:
          type: string
          description: A unique identifier for the completion
        object:
          type: string
          enum: [chat.completion]
        created:
          type: integer
          description: Unix timestamp of when the completion was created
        model:
          type: string
          description: The model used for completion
        choices:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionChoice'
        usage:
          $ref: '#/components/schemas/Usage'

    ChatCompletionChoice:
      type: object
      required:
        - index
        - message
        - finish_reason
      properties:
        index:
          type: integer
          description: The index of the choice in the list
        message:
          $ref: '#/components/schemas/ChatMessage'
        finish_reason:
          type: string
          enum: [stop, length, content_filter]
          description: The reason the model stopped generating tokens

    Usage:
      type: object
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      properties:
        prompt_tokens:
          type: integer
          description: Number of tokens in the prompt
        completion_tokens:
          type: integer
          description: Number of tokens in the completion
        total_tokens:
          type: integer
          description: Total number of tokens used

    ListModelsResponse:
      type: object
      required:
        - object
        - data
      properties:
        object:
          type: string
          enum: [list]
        data:
          type: array
          items:
            $ref: '#/components/schemas/Model'

    Model:
      type: object
      required:
        - id
        - object
        - created
        - owned_by
      properties:
        id:
          type: string
          description: The model identifier
        object:
          type: string
          enum: [model]
        created:
          type: integer
          description: Unix timestamp of when the model was created
        owned_by:
          type: string
          description: The organization that owns the model

    Error:
      type: object
      required:
        - error
      properties:
        error:
          $ref: '#/components/schemas/ErrorDetails'

    ErrorDetails:
      type: object
      required:
        - message
        - type
      properties:
        message:
          type: string
          description: A human-readable error message
        type:
          type: string
          description: The error type
        param:
          type: string
          description: The parameter that caused the error
        code:
          type: string
          description: The error code

  responses:
    BadRequest:
      description: Bad Request
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'

    Unauthorized:
      description: Unauthorized
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'

    RateLimitExceeded:
      description: Rate limit exceeded
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          examples:
            rate-limit:
              summary: Rate limit exceeded
              value:
                error:
                  message: "Rate limit exceeded. Please try again later."
                  type: rate_limit_exceeded
                  code: rate_limit_exceeded

    InternalServerError:
      description: Internal server error
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'