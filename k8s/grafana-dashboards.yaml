apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards
  namespace: monitoring
  labels:
    grafana_dashboard: "1"
data:
  helixflow-overview.json: |
    {
      "dashboard": {
        "id": null,
        "title": "HelixFlow Platform Overview",
        "tags": ["helixflow", "overview"],
        "timezone": "browser",
        "panels": [
          {
            "id": 1,
            "title": "API Gateway Requests",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(http_requests_total{job=\"api-gateway\"}[5m])",
                "legendFormat": "{{method}} {{status}}"
              }
            ]
          },
          {
            "id": 2,
            "title": "Inference Pool Performance",
            "type": "graph",
            "targets": [
              {
                "expr": "histogram_quantile(0.95, rate(model_inference_duration_seconds_bucket[5m]))",
                "legendFormat": "95th percentile latency"
              }
            ]
          },
          {
            "id": 3,
            "title": "GPU Utilization",
            "type": "graph",
            "targets": [
              {
                "expr": "gpu_utilization",
                "legendFormat": "{{gpu}} utilization"
              }
            ]
          },
          {
            "id": 4,
            "title": "Service Health",
            "type": "table",
            "targets": [
              {
                "expr": "up",
                "legendFormat": "{{job}}"
              }
            ]
          }
        ],
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "refresh": "30s"
      }
    }
  model-performance.json: |
    {
      "dashboard": {
        "id": null,
        "title": "Model Performance Metrics",
        "tags": ["helixflow", "models", "performance"],
        "timezone": "browser",
        "panels": [
          {
            "id": 1,
            "title": "Model Inference Latency by Model",
            "type": "graph",
            "targets": [
              {
                "expr": "histogram_quantile(0.95, rate(model_inference_duration_seconds_bucket{model!=\"\"}[5m])) by (model)",
                "legendFormat": "{{model}} 95th percentile"
              }
            ]
          },
          {
            "id": 2,
            "title": "Model Request Rate",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(model_requests_total[5m])",
                "legendFormat": "{{model}} requests/sec"
              }
            ]
          },
          {
            "id": 3,
            "title": "Model Error Rate",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(model_errors_total[5m]) / rate(model_requests_total[5m])",
                "legendFormat": "{{model}} error rate"
              }
            ]
          }
        ],
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "refresh": "30s"
      }
    }